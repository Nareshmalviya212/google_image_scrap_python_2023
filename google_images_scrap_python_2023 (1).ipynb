{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e843263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selenium helps you use this executable to automate Chrome\n",
    "from multiprocessing.sharedctypes import Value\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import io\n",
    "from datetime import datetime as dt\n",
    "from PIL import Image\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e972cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the driver from chromedriver website for relevant OS i.e. MAC, Windows, Debian, etc.\n",
    "PATH = 'C:/Users/91735/Downloads/chromedriver_win32/chromedriver.exe'\n",
    "wd = webdriver.Chrome(executable_path=PATH)\n",
    "\n",
    "\n",
    "def get_images_from_google(wd, delay, max_images, url):\n",
    "    def scroll_down(wd):\n",
    "        wd.execute_script(\"window.scrollBy(0,document.body.scrollHeight);\")#parameter in pixel /// scrollTo\n",
    "        time.sleep(delay)\n",
    "\n",
    "    url = url\n",
    "    wd.get(url)\n",
    "\n",
    "    image_urls = set()\n",
    "    skips = 0\n",
    "    while len(image_urls) + skips < max_images:\n",
    "        scroll_down(wd)\n",
    "        thumbnails = wd.find_elements(By.CLASS_NAME, \"Q4LuWd\")\n",
    "\n",
    "        for img in thumbnails[len(image_urls) + skips:max_images]:\n",
    "            try:\n",
    "                img.click()\n",
    "                time.sleep(delay)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            images = wd.find_elements(By.CLASS_NAME, \"n3VNCb\")\n",
    "            for image in images:\n",
    "                if image.get_attribute('src') in image_urls:\n",
    "                    max_images += 1\n",
    "                    skips += 1\n",
    "                    break\n",
    "\n",
    "                if image.get_attribute('src') and 'http' in image.get_attribute('src'):\n",
    "                    image_urls.add(image.get_attribute('src'))\n",
    "                    ##print(f\"Found {len(image_urls)}\")\n",
    "\n",
    "    return image_urls\n",
    "\n",
    "\n",
    "def download_image(down_path, url, file_name, image_type='JPEG',\n",
    "                   verbose=True):\n",
    "    try:\n",
    "        time = dt.now()\n",
    "        curr_time = time.strftime('%H:%M:%S')\n",
    "        #Content of the image will be a url\n",
    "        img_content = requests.get(url).content\n",
    "        #Get the bytes IO of the image\n",
    "        img_file = io.BytesIO(img_content)\n",
    "        #Stores the file in memory and convert to image file using Pillow\n",
    "        image = Image.open(img_file)\n",
    "        file_pth = down_path + file_name\n",
    "\n",
    "        with open(file_pth, 'wb') as file:\n",
    "            image.save(file, image_type)\n",
    "\n",
    "        if verbose == True:\n",
    "            print(f'The image: {file_pth} downloaded successfully at {curr_time}.')\n",
    "    except Exception as e:\n",
    "        print(f'Unable to download image from Google Photos due to\\n: {str(e)}')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Google search URLS\n",
    "    ij=input(\"enter \")\n",
    "    tk=ij.replace(\" \",\"+\")\n",
    "    \n",
    "    #print(ij)\n",
    "    google_urls = ['https://www.google.com/search?q='+tk+'&tbm=isch&ved=2ahUKEwi73fyn3sj3AhUD-4UKHSjyBpAQ2-cCegQIABAA&oq=alex&gs_lcp=CgNpbWcQARgAMgcIIxDvAxAnMgcIIxDvAxAnMgoIABCxAxCDARBDMgQIABBDMgQIABBDMgQIABBDMggIABCABBCxAzIECAAQQzIICAAQgAQQsQMyCAgAEIAEELEDOgUIABCABDoECAAQGDoLCAAQgAQQsQMQgwE6CAgAELEDEIMBOgcIABCxAxBDUKIHWJwLYLwUaABwAHgAgAFLiAHIApIBATWYAQCgAQGqAQtnd3Mtd2l6LWltZ8ABAQ&sclient=img&ei=g_VzYvuPJIP2lwSo5JuACQ&bih=969&biw=1920&rlz=1C1CHBF_en-GBGB924GB924&hl=en']\n",
    "    # Labels for the players\n",
    "    labels = [tk]\n",
    "\n",
    "    # Check the length of the lists\n",
    "    if len(google_urls) != len(labels):\n",
    "        raise ValueError('The length of the url list does not match the labels list.')\n",
    "\n",
    "    player_path = 'images/nottingham_forest/'\n",
    "    # Make the directory if it doesn't exist\n",
    "    for lbl in labels:\n",
    "        if not os.path.exists(player_path + lbl):\n",
    "            print(f'Making directory: {str(lbl)}')\n",
    "            os.makedirs(player_path+lbl)\n",
    "\n",
    "    for url_current, lbl in zip(google_urls, labels):\n",
    "        urls = get_images_from_google(wd, 0, 100, url_current)  #here 100 is number of images\n",
    "        # Once we have added our urls to empty set then \n",
    "        for i, url in enumerate(urls):\n",
    "            download_image(down_path=f'images/nottingham_forest/{lbl}/', \n",
    "                        url=url, \n",
    "                        file_name=str(i+1)+ '.jpg',\n",
    "                        verbose=True)\n",
    "            time.sleep(4) #its optional parameter...if you want to comment them\n",
    "    wd.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
